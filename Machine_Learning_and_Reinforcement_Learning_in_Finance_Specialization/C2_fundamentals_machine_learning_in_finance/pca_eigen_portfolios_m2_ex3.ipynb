{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigen-portfolio construction using Principal Component Analysis (PCA)\n",
    "\n",
    "### PCA via sklearn.decomposition using S&P 500 Index stock data\n",
    "\n",
    "Welcome to your 2-nd assignment in Unsupervised Machine Learning in Finance.\n",
    "\n",
    "In this assignment we look in-depth at model-free factor analysis using PCA. By model-free we mean that we do not rely on any factors such as value or momentum to decompose portfolio returns, but instead using Principal Component Analysis (PCA) to deduce structure of portfolio returns.\n",
    "\n",
    "We work with S&P 500 index stock data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. You only need to write code between the ### START CODE HERE ### and ### END CODE HERE ### comments. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run Cell\" (denoted by a play symbol) in the upper bar of the notebook. \n",
    "\n",
    "We will often specify \"(â‰ˆ X lines of code)\" in the comments to tell you about how much code you need to write. It is just a rough estimate, so don't feel bad if your code is longer or shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pandas: 0.19.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import grading\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"  pandas: %s\"% pd.__version__)\n",
    "except:\n",
    "    print(\"Missing pandas package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ONLY FOR GRADING. DO NOT EDIT ### \n",
    "submissions=dict()\n",
    "assignment_key=\"BBz-XobeEeegARIApDSa9g\" \n",
    "all_parts=[\"nvDA9\", \"ykDlW\", \"rpYVm\",\"oWy6l\",\"MWWt7\",\"3VyJD\"]\n",
    "### ONLY FOR GRADING. DO NOT EDIT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COURSERA_TOKEN = \"ZzBWPNfVAqZCwGN7\"  # the key provided to the Student under his/her email on submission page\n",
    "COURSERA_EMAIL =  \"XX\"  # the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset prices shape (3493, 419)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AEE</th>\n",
       "      <th>AEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-27</th>\n",
       "      <td>46.1112</td>\n",
       "      <td>78.9443</td>\n",
       "      <td>3.9286</td>\n",
       "      <td>4.5485</td>\n",
       "      <td>13.7898</td>\n",
       "      <td>15.6719</td>\n",
       "      <td>48.0313</td>\n",
       "      <td>10.8844</td>\n",
       "      <td>39.5477</td>\n",
       "      <td>8.1250</td>\n",
       "      <td>32.9375</td>\n",
       "      <td>33.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-28</th>\n",
       "      <td>45.8585</td>\n",
       "      <td>77.8245</td>\n",
       "      <td>3.6295</td>\n",
       "      <td>4.5485</td>\n",
       "      <td>14.2653</td>\n",
       "      <td>14.3906</td>\n",
       "      <td>47.7500</td>\n",
       "      <td>10.7143</td>\n",
       "      <td>38.5627</td>\n",
       "      <td>7.7188</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>33.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>44.5952</td>\n",
       "      <td>78.0345</td>\n",
       "      <td>3.7054</td>\n",
       "      <td>4.3968</td>\n",
       "      <td>14.5730</td>\n",
       "      <td>13.7656</td>\n",
       "      <td>46.7500</td>\n",
       "      <td>10.6576</td>\n",
       "      <td>37.3807</td>\n",
       "      <td>7.6406</td>\n",
       "      <td>32.5625</td>\n",
       "      <td>33.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>47.8377</td>\n",
       "      <td>80.7640</td>\n",
       "      <td>3.5804</td>\n",
       "      <td>4.5333</td>\n",
       "      <td>14.7128</td>\n",
       "      <td>13.9688</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>10.8844</td>\n",
       "      <td>37.9717</td>\n",
       "      <td>7.9219</td>\n",
       "      <td>32.5625</td>\n",
       "      <td>33.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>51.5434</td>\n",
       "      <td>83.4934</td>\n",
       "      <td>3.5290</td>\n",
       "      <td>4.5788</td>\n",
       "      <td>14.7968</td>\n",
       "      <td>15.3281</td>\n",
       "      <td>48.1250</td>\n",
       "      <td>10.6576</td>\n",
       "      <td>35.9032</td>\n",
       "      <td>7.9688</td>\n",
       "      <td>32.5625</td>\n",
       "      <td>33.6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A       AA    AAPL     ABC      ABT     ADBE      ADI  \\\n",
       "2000-01-27  46.1112  78.9443  3.9286  4.5485  13.7898  15.6719  48.0313   \n",
       "2000-01-28  45.8585  77.8245  3.6295  4.5485  14.2653  14.3906  47.7500   \n",
       "2000-01-31  44.5952  78.0345  3.7054  4.3968  14.5730  13.7656  46.7500   \n",
       "2000-02-01  47.8377  80.7640  3.5804  4.5333  14.7128  13.9688  49.0000   \n",
       "2000-02-02  51.5434  83.4934  3.5290  4.5788  14.7968  15.3281  48.1250   \n",
       "\n",
       "                ADM      ADP    ADSK      AEE      AEP  \n",
       "2000-01-27  10.8844  39.5477  8.1250  32.9375  33.5625  \n",
       "2000-01-28  10.7143  38.5627  7.7188  32.3125  33.0000  \n",
       "2000-01-31  10.6576  37.3807  7.6406  32.5625  33.5000  \n",
       "2000-02-01  10.8844  37.9717  7.9219  32.5625  33.6875  \n",
       "2000-02-02  10.6576  35.9032  7.9688  32.5625  33.6250  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "asset_prices = pd.read_csv('/home/jovyan/work/readonly/spx_holdings_and_spx_closeprice.csv',\n",
    "                     date_parser=lambda dt: pd.to_datetime(dt, format='%Y-%m-%d'),\n",
    "                     index_col = 0).dropna()\n",
    "n_stocks_show = 12\n",
    "print('Asset prices shape', asset_prices.shape)\n",
    "asset_prices.iloc[:, :n_stocks_show].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last column contains SPX index prices:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STJ</th>\n",
       "      <th>SVU</th>\n",
       "      <th>SWY</th>\n",
       "      <th>TEG</th>\n",
       "      <th>TER</th>\n",
       "      <th>TGNA</th>\n",
       "      <th>THC</th>\n",
       "      <th>X</th>\n",
       "      <th>MAR.1</th>\n",
       "      <th>SPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-27</th>\n",
       "      <td>5.5918</td>\n",
       "      <td>86.6178</td>\n",
       "      <td>26.3983</td>\n",
       "      <td>11.3873</td>\n",
       "      <td>65.8677</td>\n",
       "      <td>22.1921</td>\n",
       "      <td>60.9705</td>\n",
       "      <td>20.7086</td>\n",
       "      <td>12.2457</td>\n",
       "      <td>1398.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-28</th>\n",
       "      <td>5.4520</td>\n",
       "      <td>82.4218</td>\n",
       "      <td>27.4137</td>\n",
       "      <td>11.2230</td>\n",
       "      <td>60.3487</td>\n",
       "      <td>21.7558</td>\n",
       "      <td>62.3032</td>\n",
       "      <td>20.1183</td>\n",
       "      <td>12.0742</td>\n",
       "      <td>1360.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>5.5499</td>\n",
       "      <td>86.3181</td>\n",
       "      <td>28.2444</td>\n",
       "      <td>11.0862</td>\n",
       "      <td>62.1484</td>\n",
       "      <td>22.0533</td>\n",
       "      <td>60.6373</td>\n",
       "      <td>19.5772</td>\n",
       "      <td>12.1722</td>\n",
       "      <td>1394.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>5.4240</td>\n",
       "      <td>83.0212</td>\n",
       "      <td>28.7982</td>\n",
       "      <td>11.1683</td>\n",
       "      <td>67.3674</td>\n",
       "      <td>22.2120</td>\n",
       "      <td>60.4708</td>\n",
       "      <td>19.5772</td>\n",
       "      <td>12.5151</td>\n",
       "      <td>1409.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>5.3541</td>\n",
       "      <td>81.5226</td>\n",
       "      <td>28.6136</td>\n",
       "      <td>11.1956</td>\n",
       "      <td>68.9271</td>\n",
       "      <td>22.6483</td>\n",
       "      <td>62.4698</td>\n",
       "      <td>19.5281</td>\n",
       "      <td>12.3192</td>\n",
       "      <td>1409.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               STJ      SVU      SWY      TEG      TER     TGNA      THC  \\\n",
       "2000-01-27  5.5918  86.6178  26.3983  11.3873  65.8677  22.1921  60.9705   \n",
       "2000-01-28  5.4520  82.4218  27.4137  11.2230  60.3487  21.7558  62.3032   \n",
       "2000-01-31  5.5499  86.3181  28.2444  11.0862  62.1484  22.0533  60.6373   \n",
       "2000-02-01  5.4240  83.0212  28.7982  11.1683  67.3674  22.2120  60.4708   \n",
       "2000-02-02  5.3541  81.5226  28.6136  11.1956  68.9271  22.6483  62.4698   \n",
       "\n",
       "                  X    MAR.1      SPX  \n",
       "2000-01-27  20.7086  12.2457  1398.56  \n",
       "2000-01-28  20.1183  12.0742  1360.16  \n",
       "2000-01-31  19.5772  12.1722  1394.46  \n",
       "2000-02-01  19.5772  12.5151  1409.28  \n",
       "2000-02-02  19.5281  12.3192  1409.12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Last column contains SPX index prices:')\n",
    "asset_prices.iloc[:, -10:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 (Asset Returns Calculation)\n",
    "**Instructions:**\n",
    "\n",
    "Calculate percent returns, also known as simple returns using asse_prices. assign the result to variable asset_returns. Keep only not-nan values in the resulting pandas.DataFrame\n",
    "\n",
    "Calculate de-meaned returns and scale them by standard deviation $\\sigma$. Assign result to normed_returns variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute stock returns and normalize stock returns data by subtracting the mean and dividing by standard diviation. This normalization is required by PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STJ</th>\n",
       "      <th>SVU</th>\n",
       "      <th>SWY</th>\n",
       "      <th>TEG</th>\n",
       "      <th>TER</th>\n",
       "      <th>TGNA</th>\n",
       "      <th>THC</th>\n",
       "      <th>X</th>\n",
       "      <th>MAR.1</th>\n",
       "      <th>SPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-16</th>\n",
       "      <td>0.852722</td>\n",
       "      <td>0.965219</td>\n",
       "      <td>-1.168885</td>\n",
       "      <td>0.884751</td>\n",
       "      <td>0.095865</td>\n",
       "      <td>0.656639</td>\n",
       "      <td>0.180014</td>\n",
       "      <td>-0.238498</td>\n",
       "      <td>0.465047</td>\n",
       "      <td>0.467931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-17</th>\n",
       "      <td>0.275173</td>\n",
       "      <td>0.517307</td>\n",
       "      <td>-0.086106</td>\n",
       "      <td>-0.306213</td>\n",
       "      <td>0.589689</td>\n",
       "      <td>-0.118610</td>\n",
       "      <td>-0.549523</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>-0.260013</td>\n",
       "      <td>-0.247921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-18</th>\n",
       "      <td>0.864485</td>\n",
       "      <td>0.509435</td>\n",
       "      <td>0.600714</td>\n",
       "      <td>1.210605</td>\n",
       "      <td>-0.190024</td>\n",
       "      <td>0.925461</td>\n",
       "      <td>0.756998</td>\n",
       "      <td>0.058428</td>\n",
       "      <td>0.952458</td>\n",
       "      <td>1.252703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-19</th>\n",
       "      <td>0.210069</td>\n",
       "      <td>0.399574</td>\n",
       "      <td>-0.100159</td>\n",
       "      <td>-0.757419</td>\n",
       "      <td>-0.208023</td>\n",
       "      <td>0.304913</td>\n",
       "      <td>-0.772205</td>\n",
       "      <td>1.544228</td>\n",
       "      <td>-0.167775</td>\n",
       "      <td>-0.056358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-20</th>\n",
       "      <td>0.827306</td>\n",
       "      <td>0.748420</td>\n",
       "      <td>0.372443</td>\n",
       "      <td>1.048113</td>\n",
       "      <td>0.264046</td>\n",
       "      <td>0.436874</td>\n",
       "      <td>0.320641</td>\n",
       "      <td>-0.740854</td>\n",
       "      <td>0.373717</td>\n",
       "      <td>0.353859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STJ       SVU       SWY       TEG       TER      TGNA  \\\n",
       "2013-12-16  0.852722  0.965219 -1.168885  0.884751  0.095865  0.656639   \n",
       "2013-12-17  0.275173  0.517307 -0.086106 -0.306213  0.589689 -0.118610   \n",
       "2013-12-18  0.864485  0.509435  0.600714  1.210605 -0.190024  0.925461   \n",
       "2013-12-19  0.210069  0.399574 -0.100159 -0.757419 -0.208023  0.304913   \n",
       "2013-12-20  0.827306  0.748420  0.372443  1.048113  0.264046  0.436874   \n",
       "\n",
       "                 THC         X     MAR.1       SPX  \n",
       "2013-12-16  0.180014 -0.238498  0.465047  0.467931  \n",
       "2013-12-17 -0.549523  0.025268 -0.260013 -0.247921  \n",
       "2013-12-18  0.756998  0.058428  0.952458  1.252703  \n",
       "2013-12-19 -0.772205  1.544228 -0.167775 -0.056358  \n",
       "2013-12-20  0.320641 -0.740854  0.373717  0.353859  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_returns = pd.DataFrame(data=np.zeros(shape=(len(asset_prices.index), asset_prices.shape[1])), \n",
    "                             columns=asset_prices.columns.values,\n",
    "                             index=asset_prices.index)\n",
    "normed_returns = asset_returns\n",
    "### START CODE HERE ### (â‰ˆ 4 lines of code)\n",
    "# normed_returns is pandas.DataFrame that should contain normalized returns\n",
    "asset_returns = asset_prices.sort_index().pct_change().dropna()\n",
    "# from sklearn import preprocessing\n",
    "# x = asset_returns.values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# normed_returns = pd.DataFrame(x_scaled)\n",
    "normed_returns=(asset_returns-asset_returns.mean())/asset_returns.std()\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "normed_returns.iloc[-5:, -10:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission successful, please check on the coursera grader page for the status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.19005437, -0.51371017, -2.71470869, -0.04977943,  2.18293305,\n",
       "       -2.68413088, -0.21246093, -0.76699639, -1.5407309 , -1.80394666,\n",
       "       -1.37299129, -0.99416907,  0.16136183,  0.72980366,  0.63485621,\n",
       "       -0.72131907, -0.01302927, -0.80797756,  0.39923062, -0.75893259,\n",
       "       -1.43444651, -1.12783867, -1.29385343, -0.44802859, -2.13973399,\n",
       "        0.58949813, -0.87826364,  0.31428572, -1.08060243, -0.31367868,\n",
       "        0.11819333, -1.8686777 , -1.87275168, -0.22608376, -0.04189121,\n",
       "       -0.02136145, -0.60458719, -1.43087396, -1.16679677, -1.65594274,\n",
       "       -0.50493241, -1.5196492 , -0.36359946, -0.58859176, -0.73289901,\n",
       "        0.87654672, -3.12410596, -1.33977245, -1.33866029, -0.53051976,\n",
       "       -1.28309222, -2.2171311 ,  1.75785074,  0.22815795, -0.48093428,\n",
       "       -0.21160476, -1.39163378, -1.8907977 , -1.26523275, -0.90790361,\n",
       "        1.20007622, -1.13783598, -1.06735573, -1.49029484,  1.65191927,\n",
       "       -0.94841616,  3.36936561, -0.82344479,  1.76591258,  0.0414378 ,\n",
       "       -2.73686257, -0.93544592,  0.02499427, -0.52726361, -0.34692757,\n",
       "       -3.31744267, -1.10532688, -0.797565  , -0.45450193,  1.58036671,\n",
       "       -1.05535759, -0.19732619, -0.85221605, -3.09447476, -2.41199636,\n",
       "       -0.9392503 , -1.88367011, -2.73709342, -2.97077299, -0.52321504,\n",
       "       -0.7113052 ,  2.02582123, -1.26160414, -3.24554378, -1.04361909,\n",
       "       -0.21374985,  0.86653839, -0.53475603,  0.92652973, -0.51024788])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part_1=list(normed_returns.iloc[0,: 100].as_matrix().squeeze())\n",
    "try:\n",
    "    part1 = \" \".join(map(repr, part_1))\n",
    "except TypeError:\n",
    "    part1 = repr(part_1)\n",
    "submissions[all_parts[0]]=part1\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:1],all_parts,submissions)\n",
    "normed_returns.iloc[0,: 100].as_matrix().squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: (3055, 419)\n",
      "Test dataset: (437, 419)\n"
     ]
    }
   ],
   "source": [
    "train_end = datetime.datetime(2012, 3, 26) \n",
    "\n",
    "df_train = None\n",
    "df_test = None\n",
    "df_raw_train = None\n",
    "df_raw_test = None\n",
    "\n",
    "df_train = normed_returns[normed_returns.index <= train_end].copy()\n",
    "df_test = normed_returns[normed_returns.index > train_end].copy()\n",
    "\n",
    "df_raw_train = asset_returns[asset_returns.index <= train_end].copy()\n",
    "df_raw_test = asset_returns[asset_returns.index > train_end].copy()\n",
    "\n",
    "print('Train dataset:', df_train.shape)\n",
    "print('Test dataset:', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute PCA using all available data. Once we do have PCA computed we fix variance explained at some number and see what is the smallest number of components needed to explain this variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 (PCA fitting)\n",
    "**Instructions:**\n",
    "- Calculate covariance matrix using training data set, i.e. **df_train** for all assets.  Assign results to **cov_matrix**.\n",
    "- Calculate covariance matrix using training data set, i.e. **df_raw_train** for all assets.  Assign results to **cov_matrix_raw**.\n",
    "- Use scikit-learn PCA to fit PCA model to **cov_matrix**. Assign fitted model to **pca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 components explain 80.00% of variance\n"
     ]
    }
   ],
   "source": [
    "import sklearn.decomposition\n",
    "import seaborn as sns\n",
    "\n",
    "stock_tickers = normed_returns.columns.values[:-1]\n",
    "assert 'SPX' not in stock_tickers, \"By accident included SPX index\"\n",
    "\n",
    "n_tickers = len(stock_tickers)\n",
    "pca = None\n",
    "cov_matrix = pd.DataFrame(data=np.ones(shape=(n_tickers, n_tickers)), columns=stock_tickers)\n",
    "cov_matrix_raw = cov_matrix\n",
    "\n",
    "if df_train is not None and df_raw_train is not None:\n",
    "    stock_tickers = asset_returns.columns.values[:-1]\n",
    "    assert 'SPX' not in stock_tickers, \"By accident included SPX index\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ 2-3 lines of code)\n",
    "    \n",
    "    # computing PCA on S&P 500 stocks\n",
    "    cov_matrix = df_train.loc[:, df_train.columns != 'SPX'].cov()\n",
    "    cov_matrix_raw = df_raw_train.loc[:, df_raw_train.columns != 'SPX'].cov()\n",
    "    \n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    pca.fit_transform(cov_matrix)    \n",
    "\n",
    "    # not normed covariance matrix\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    cov_raw_df = pd.DataFrame({'Variance': np.diag(cov_matrix_raw)}, index=stock_tickers)    \n",
    "    # cumulative variance explained\n",
    "    var_threshold = 0.8\n",
    "    var_explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "    num_comp = np.where(np.logical_not(var_explained < var_threshold))[0][0] + 1  # +1 due to zero based-arrays\n",
    "    print('%d components explain %.2f%% of variance' %(num_comp, 100* var_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part_2 = np.diag(cov_matrix[: 100])\n",
    "try:\n",
    "    part2 = \" \".join(map(repr, part_2))\n",
    "except TypeError:\n",
    "    part2 = repr(part_2)\n",
    "submissions[all_parts[1]]=part2\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:2],all_parts,submissions)\n",
    "### GRADED PART (DO NOT EDIT) ###\n",
    "np.diag(cov_matrix[: 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if pca is not None:\n",
    "    bar_width = 0.9\n",
    "    n_asset = int((1 / 10) * normed_returns.shape[1])\n",
    "    x_indx = np.arange(n_asset)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(12, 4)\n",
    "    # Eigenvalues are measured as percentage of explained variance.\n",
    "    rects = ax.bar(x_indx, pca.explained_variance_ratio_[:n_asset], bar_width, color='deepskyblue')\n",
    "    ax.set_xticks(x_indx + bar_width / 2)\n",
    "    ax.set_xticklabels(list(range(n_asset)), rotation=45)\n",
    "    ax.set_title('Percent variance explained')\n",
    "    ax.legend((rects[0],), ('Percent variance explained by principal components',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if pca is not None:\n",
    "    projected = pca.fit_transform(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 (Eigen-portfolios construction)\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "We now look a the first two eigen portfolios. We use definition of eigen portfolios as provided by Avellaneda \n",
    "http://math.nyu.edu/faculty/avellane/AvellanedaLeeStatArb20090616.pdf\n",
    "\n",
    "Following Avellaneda we define eigen portfolio weights as:\n",
    "$$Q_i^{(j)} = \\frac{v_i^{(j)}}{\\sigma_i}$$\n",
    "\n",
    "where $j$ is the index of eigen portfolio and $v_i$ is the i-th element of j-th eigen vector.\n",
    "\n",
    "In the code the pca.components_ are the Principal axes in feature space, representing the directions of maximum variance in the data. The components are sorted by explained_variance_.\n",
    "\n",
    "**Hint:** do not forget to normalize portfolio wieghts such they sum up to 1.\n",
    "\n",
    "Assign **pc_w** to be weights of the first eigen portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the first two eigen-portfolio weights# the fi \n",
    "# first component\n",
    "# get the Principal components\n",
    "pc_w = np.zeros(len(stock_tickers))\n",
    "eigen_prtf1 = pd.DataFrame(data ={'weights': pc_w.squeeze()*100}, index = stock_tickers)\n",
    "if pca is not None:\n",
    "    pcs = pca.components_\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ 1-2 lines of code)\n",
    "    # normalized to 1 \n",
    "    pc_w = pcs[:,0]/sum(pcs[:,0])\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    eigen_prtf1 = pd.DataFrame(data ={'weights': pc_w.squeeze()*100}, index = stock_tickers)\n",
    "    eigen_prtf1.sort_values(by=['weights'], ascending=False, inplace=True)\n",
    "    print('Sum of weights of first eigen-portfolio: %.2f' % np.sum(eigen_prtf1))\n",
    "    eigen_prtf1.plot(title='First eigen-portfolio weights', \n",
    "                     figsize=(12,6), \n",
    "                     xticks=range(0, len(stock_tickers),10), \n",
    "                     rot=45, \n",
    "                     linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part_3 = list(eigen_prtf1.squeeze().values)\n",
    "try:\n",
    "    part3 = \" \".join(map(repr, part_3))\n",
    "except TypeError:\n",
    "    part3 = repr(part_3)\n",
    "submissions[all_parts[2]]=part3\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:3],all_parts,submissions)\n",
    "eigen_prtf1.squeeze().values\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort the first two eigen portfolio weights and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc_w = np.zeros(len(stock_tickers))\n",
    "eigen_prtf2 = pd.DataFrame(data ={'weights': pc_w.squeeze()*100}, index = stock_tickers)\n",
    "\n",
    "if pca is not None:\n",
    "    pcs = pca.components_\n",
    "    \n",
    "    ### START CODE HERE ### (â‰ˆ 1-2 lines of code)\n",
    "    # normalized to 1 \n",
    "    pc_w = pcs[:,1]/sum(pcs[:,1])\n",
    "\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    eigen_prtf2 = pd.DataFrame(data ={'weights': pc_w.squeeze()*100}, index = stock_tickers)\n",
    "    eigen_prtf2.sort_values(by=['weights'], ascending=False, inplace=True)\n",
    "    print('Sum of weights of second eigen-portfolio: %.2f' % np.sum(eigen_prtf2))\n",
    "    eigen_prtf2.plot(title='Second eigen-portfolio weights',\n",
    "                     figsize=(12,6), \n",
    "                     xticks=range(0, len(stock_tickers),10), \n",
    "                     rot=45, \n",
    "                     linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part_4 = list(eigen_prtf2.as_matrix().squeeze())\n",
    "try:\n",
    "    part4 = \" \".join(map(repr, part_4))\n",
    "except TypeError:\n",
    "    part4 = repr(part_4)\n",
    "submissions[all_parts[3]]=part4\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:4],all_parts,submissions)\n",
    "eigen_prtf2.as_matrix().squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 (Compute performance of several eigen portfolios)\n",
    "\n",
    "**Instructions:**\n",
    "- Implement sharpe_ratio() function. The function takes ts_returns argument of type pd.Series and returns a tuple of annualized return, annualized vol, and annualized sharpe ratio, where sharpe ratio is defined as annualized return divided by annualized volatility \n",
    "- find portfolio (an index into sharpe_metric) that has the highest sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw_test+1\n",
    "\n",
    "np.dot(df_raw_test.loc[:, eigen_prtf1.index], eigen_prtf1 / 100)\n",
    "# df_raw_test.loc[:, eigen_prtf1.index].shape\n",
    "\n",
    "asset_prices.index.max()\n",
    "asset_prices.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sharpe_ratio(ts_returns, periods_per_year=252):\n",
    "    \"\"\"\n",
    "    sharpe_ratio - Calculates annualized return, annualized vol, and annualized sharpe ratio, \n",
    "                    where sharpe ratio is defined as annualized return divided by annualized volatility \n",
    "                    \n",
    "    Arguments:\n",
    "    ts_returns - pd.Series of returns of a single eigen portfolio\n",
    "    \n",
    "    Return:\n",
    "    a tuple of three doubles: annualized return, volatility, and sharpe ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    annualized_return = 0.\n",
    "    annualized_vol = 0.\n",
    "    annualized_sharpe = 0.\n",
    "    \n",
    "    ### START CODE HERE ### (â‰ˆ 4-5 lines of code)\n",
    "    ### ...\n",
    "#     annualized_return = (np.prod(1 + ts_returns)/ (periods_per_year/ts_returns.shape[0])) - 1\n",
    "    annualized_return = np.power(np.prod(1 + ts_returns), (periods_per_year/ts_returns.shape[0])) - 1\n",
    "#     annualized_vol = ts_returns.std() + np.sqrt(periods_per_year)\n",
    "    annualized_vol = ts_returns.std()*np.sqrt(periods_per_year)\n",
    "    annualized_sharpe = annualized_return / annualized_vol  \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return annualized_return, annualized_vol, annualized_sharpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the annualized return, volatility, and Sharpe ratio of the first two eigen portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if df_raw_test is not None:\n",
    "    eigen_prtf1_returns = np.dot(df_raw_test.loc[:, eigen_prtf1.index], eigen_prtf1 / 100)\n",
    "    eigen_prtf1_returns = pd.Series(eigen_prtf1_returns.squeeze(), index=df_test.index)\n",
    "    er, vol, sharpe = sharpe_ratio(eigen_prtf1_returns)\n",
    "    print('First eigen-portfolio:\\nReturn = %.2f%%\\nVolatility = %.2f%%\\nSharpe = %.2f' % (er*100, vol*100, sharpe))\n",
    "    year_frac = (eigen_prtf1_returns.index[-1] - eigen_prtf1_returns.index[0]).days / 252\n",
    "\n",
    "    df_plot = pd.DataFrame({'PC1': eigen_prtf1_returns, 'SPX': df_raw_test.loc[:, 'SPX']}, index=df_test.index)\n",
    "    np.cumprod(df_plot + 1).plot(title='Returns of the market-cap weighted index vs. First eigen-portfolio', \n",
    "                             figsize=(12,6), linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if df_raw_test is not None:\n",
    "    eigen_prtf2_returns = np.dot(df_raw_test.loc[:, eigen_prtf2.index], eigen_prtf2 / 100)\n",
    "    eigen_prtf2_returns = pd.Series(eigen_prtf2_returns.squeeze(), index=df_test.index)\n",
    "    er, vol, sharpe = sharpe_ratio(eigen_prtf2_returns)\n",
    "    print('Second eigen-portfolio:\\nReturn = %.2f%%\\nVolatility = %.2f%%\\nSharpe = %.2f' % (er*100, vol*100, sharpe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the exercise of computing Sharpe ratio for the first N portfolios and select portfolio with the highest postive Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_portfolios = 120\n",
    "annualized_ret = np.array([0.] * n_portfolios)\n",
    "sharpe_metric = np.array([0.] * n_portfolios)\n",
    "annualized_vol = np.array([0.] * n_portfolios)\n",
    "idx_highest_sharpe = 0 # index into sharpe_metric which identifies a portfolio with rhe highest Sharpe ratio\n",
    "    \n",
    "if pca is not None:\n",
    "#     pcs = pca.components_    \n",
    "    for ix in range(n_portfolios):\n",
    "        \n",
    "        ### START CODE HERE ### (â‰ˆ 4-5 lines of code)\n",
    "        # normalized to 1 \n",
    "        pc_w = pcs[:,ix]/sum(pcs[:,ix])\n",
    "\n",
    "        eigen_prtfi = pd.DataFrame(data ={'weights': pc_w.squeeze()*100}, index = stock_tickers)\n",
    "        eigen_prtfi.sort_values(by=['weights'], ascending=False, inplace=True)    \n",
    "        \n",
    "        eigen_prtfi_returns = np.dot(df_raw_test.loc[:, eigen_prtfi.index], eigen_prtfi / 100)\n",
    "        eigen_prtfi_returns = pd.Series(eigen_prtfi_returns.squeeze(), index=df_test.index)\n",
    "        annualized_ret[ix], annualized_vol[ix], annualized_vol[ix] = sharpe_ratio(eigen_prtfi_returns)     \n",
    "#         er, vol, sharpe = sharpe_ratio(eigen_prtf2_returns)        \n",
    "#         pc_w = pcs[:, ix] / sum(pcs[:, ix])\n",
    "        \n",
    "        eigen_prtf = pd.DataFrame(data ={'weights': pc_w.squeeze()*100}, index = stock_tickers)\n",
    "        eigen_prtf.sort_values(by=['weights'], ascending=False, inplace=True)\n",
    "        eigen_prtf = eigen_prtfi\n",
    "        eigen_returns = np.dot(df_raw_test.loc[:, eigen_prtf.index], eigen_prtf / 100)\n",
    "        eigen_returns = pd.Series(eigen_returns.squeeze(), index=df_test.index)\n",
    "        annualized_ret[ix], annualized_vol[ix], sharpe_metric[ix] = sharpe_ratio(eigen_returns)\n",
    "                \n",
    "            \n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    \n",
    "    # find portfolio with the highest Sharpe ratio\n",
    "    ### START CODE HERE ### (â‰ˆ 2-3 lines of code)\n",
    "    ### ...\n",
    "    idx_highest_sharpe = np.nanargmax(sharpe_metric)\n",
    "#     idx_highest_sharpe = np.argmax(sharpe_metric)\n",
    "#     sharpe_metric.dropna(inplace=True)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    print('Eigen portfolio #%d with the highest Sharpe. Return %.2f%%, vol = %.2f%%, Sharpe = %.2f' % \n",
    "          (idx_highest_sharpe,\n",
    "           annualized_ret[idx_highest_sharpe]*100, \n",
    "           annualized_vol[idx_highest_sharpe]*100, \n",
    "           sharpe_metric[idx_highest_sharpe]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(12, 4)\n",
    "    ax.plot(sharpe_metric, linewidth=3)\n",
    "    ax.set_title('Sharpe ratio of eigen-portfolios')\n",
    "    ax.set_ylabel('Sharpe ratio')\n",
    "    ax.set_xlabel('Portfolios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data={'Return': annualized_ret, 'Vol': annualized_vol, 'Sharpe': sharpe_metric})\n",
    "results.sort_values(by=['Sharpe'], ascending=False, inplace=True)\n",
    "#---------------------------------------------\n",
    "# you need this to fully pass\n",
    "print(results.shape)\n",
    "results.dropna(inplace=True)\n",
    "results.dropna(how = 'any', inplace = True)\n",
    "print(results.shape)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part_5 = list(results.iloc[:, 1].values.squeeze())\n",
    "try:\n",
    "    part5 = \" \".join(map(repr, part_5))\n",
    "except TypeError:\n",
    "    part5 = repr(part_5)\n",
    "submissions[all_parts[4]]=part5\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:5],all_parts,submissions)\n",
    "results.iloc[:, 1].values.squeeze()\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part6 = str(idx_highest_sharpe)\n",
    "submissions[all_parts[5]]=part6\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:6],all_parts,submissions)\n",
    "idx_highest_sharpe\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "course_slug": "machine-learning-in-finance"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
